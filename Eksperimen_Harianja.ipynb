{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a412a40",
   "metadata": {},
   "source": [
    "## 1. Perkenalan Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fa804f",
   "metadata": {},
   "source": [
    "Tahap pertama, Anda harus mencari dan menggunakan dataset dengan ketentuan sebagai berikut:\n",
    "\n",
    "Sumber Dataset:\n",
    "Dataset dapat diperoleh dari berbagai sumber, seperti public repositories (Kaggle, UCI ML Repository, Open Data) atau data primer yang Anda kumpulkan sendiri."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7f6906",
   "metadata": {},
   "source": [
    "## 2. Import Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08f8aea",
   "metadata": {},
   "source": [
    "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning atau deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1b8675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7c2c88",
   "metadata": {},
   "source": [
    "## 3. Memuat Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa4e8d2",
   "metadata": {},
   "source": [
    "Pada tahap ini, Anda perlu memuat dataset ke dalam notebook. Jika dataset dalam format CSV, Anda bisa menggunakan pustaka pandas untuk membacanya. Pastikan untuk mengecek beberapa baris awal dataset untuk memahami strukturnya dan memastikan data telah dimuat dengan benar.\n",
    "\n",
    "Jika dataset berada di Google Drive, pastikan Anda menghubungkan Google Drive ke Colab terlebih dahulu. Setelah dataset berhasil dimuat, langkah berikutnya adalah memeriksa kesesuaian data dan siap untuk dianalisis lebih lanjut.\n",
    "\n",
    "Jika dataset berupa unstructured data, silakan sesuaikan dengan format seperti kelas Machine Learning Pengembangan atau Machine Learning Terapan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06c192a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset berhasil dimuat!\n"
     ]
    }
   ],
   "source": [
    "# Memuat dataset langsung dari folder data_raw\n",
    "df = pd.read_csv('data_raw/hour.csv')\n",
    "\n",
    "print(\"Dataset berhasil dimuat!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d974cf9",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40195c2",
   "metadata": {},
   "source": [
    "Pada tahap ini, Anda akan melakukan Exploratory Data Analysis (EDA) untuk memahami karakteristik dataset.\n",
    "\n",
    "Tujuan dari EDA adalah untuk memperoleh wawasan awal yang mendalam mengenai data dan menentukan langkah selanjutnya dalam analisis atau pemodelan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c17121f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <td>cnt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>2011-01-01</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>6</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0.24</th>\n",
       "      <th>0.2879</th>\n",
       "      <th>0.81</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>2011-01-01</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>6</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0.22</th>\n",
       "      <th>0.2727</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0</th>\n",
       "      <th>8</th>\n",
       "      <th>32</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>2011-01-01</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>6</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0.22</th>\n",
       "      <th>0.2727</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0</th>\n",
       "      <th>5</th>\n",
       "      <th>27</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>2011-01-01</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>6</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0.24</th>\n",
       "      <th>0.2879</th>\n",
       "      <th>0.75</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                        <<<<<<< HEAD\n",
       "instant dteday     season yr mnth hr holiday weekday workingday weathersit temp atemp  hum  windspeed casual registered          cnt\n",
       "1       2011-01-01 1      0  1    0  0       6       0          1          0.24 0.2879 0.81 0         3      13                   16\n",
       "2       2011-01-01 1      0  1    1  0       6       0          1          0.22 0.2727 0.8  0         8      32                   40\n",
       "3       2011-01-01 1      0  1    2  0       6       0          1          0.22 0.2727 0.8  0         5      27                   32\n",
       "4       2011-01-01 1      0  1    3  0       6       0          1          0.24 0.2879 0.75 0         3      10                   13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Informasi Dataset ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 52143 entries, ('instant', 'dteday', 'season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'casual', 'registered') to ('>>>>>>> 459092ab500e9e2fab2af708fcd399ac5495db9d', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan)\n",
      "Data columns (total 1 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   <<<<<<< HEAD  52140 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 2.1+ MB\n",
      "\n",
      "--- Statistik Deskriptif ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       <<<<<<< HEAD\n",
       "count         52140\n",
       "unique          870\n",
       "top               5\n",
       "freq            780"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Jumlah Missing Values ---\n",
      "<<<<<<< HEAD    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Melihat 5 baris pertama data\n",
    "display(df.head())\n",
    "\n",
    "# Melihat informasi tipe data dan jumlah missing values\n",
    "print(\"\\n--- Informasi Dataset ---\")\n",
    "df.info()\n",
    "\n",
    "# Melihat statistik deskriptif dasar (rata-rata, nilai min/max, dll)\n",
    "print(\"\\n--- Statistik Deskriptif ---\")\n",
    "display(df.describe())\n",
    "\n",
    "# Mengecek total nilai yang kosong (missing values) di setiap kolom\n",
    "print(\"\\n--- Jumlah Missing Values ---\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fae276",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f2aa03",
   "metadata": {},
   "source": [
    "Pada tahap ini, data preprocessing adalah langkah penting untuk memastikan kualitas data sebelum digunakan dalam model machine learning.\n",
    "\n",
    "Jika Anda menggunakan data teks, data mentah sering kali mengandung nilai kosong, duplikasi, atau rentang nilai yang tidak konsisten, yang dapat memengaruhi kinerja model. Oleh karena itu, proses ini bertujuan untuk membersihkan dan mempersiapkan data agar analisis berjalan optimal.\n",
    "\n",
    "Berikut adalah tahapan-tahapan yang bisa dilakukan, tetapi tidak terbatas pada:\n",
    "\n",
    "Menghapus atau Menangani Data Kosong (Missing Values)\n",
    "Menghapus Data Duplikat\n",
    "Normalisasi atau Standarisasi Fitur\n",
    "Deteksi dan Penanganan Outlier\n",
    "Encoding Data Kategorikal\n",
    "Binning (Pengelompokan Data)\n",
    "Cukup sesuaikan dengan karakteristik data yang kamu gunakan yah. Khususnya ketika kami menggunakan data tidak terstruktur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38ccfc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Terjadi kesalahan: name 'load_data' is not defined\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Fungsi utama untuk melakukan pembersihan dan transformasi data.\n",
    "    Langkah ini harus sama dengan apa yang dilakukan di file .ipynb\n",
    "    \"\"\"\n",
    "    print(\"Mulai proses preprocessing data...\")\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # 1. Menghapus kolom yang tidak relevan sebagai fitur\n",
    "    # 'instant' adalah index, 'dteday' sudah diwakili kolom 'yr', 'mnth', 'weekday'\n",
    "    cols_to_drop = ['instant', 'dteday']\n",
    "    df_clean = df_clean.drop(columns=cols_to_drop, errors='ignore')\n",
    "    \n",
    "    # 2. Mencegah Data Leakage (Kebocoran Data)\n",
    "    # Target kita adalah 'cnt' (total sewa). Kolom 'casual' + 'registered' = 'cnt'\n",
    "    # Jika fitur ini dimasukkan, model akan curang. Jadi harus dihapus.\n",
    "    leakage_cols = ['casual', 'registered']\n",
    "    df_clean = df_clean.drop(columns=leakage_cols, errors='ignore')\n",
    "    \n",
    "    # 3. Menangani Missing Values (Meskipun data ini biasanya bersih, ini best practice)\n",
    "    df_clean = df_clean.dropna()\n",
    "    \n",
    "    print(\"Preprocessing selesai. Kolom yang tersisa:\")\n",
    "    print(df_clean.columns.tolist())\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "def save_data(df, output_path):\n",
    "    \"\"\"Fungsi untuk menyimpan data yang sudah diproses.\"\"\"\n",
    "    # Pastikan folder output ada\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Data bersih berhasil disimpan di {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Tentukan path file input dan output sesuai struktur folder GitHub kamu\n",
    "    INPUT_PATH = \"data_raw/hour.csv\"\n",
    "    OUTPUT_PATH = \"data_preprocessing/hour_cleaned.csv\"\n",
    "    \n",
    "    # Jalankan pipeline\n",
    "    try:\n",
    "        raw_data = load_data(INPUT_PATH)\n",
    "        cleaned_data = preprocess_data(raw_data)\n",
    "        save_data(cleaned_data, OUTPUT_PATH)\n",
    "        print(\"ðŸŽ‰ Pipeline otomatisasi berhasil dieksekusi!\")\n",
    "    except Exception as e:\n",
    "        \n",
    "        print(f\"âŒ Terjadi kesalahan: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
